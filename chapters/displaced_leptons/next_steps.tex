\section{Next steps}
\label{next_steps}
The analysis presented here will likely stand for several years as the most sensitive search for new long-lived particles that produce pairs of displaced leptons that are not required to form a common vertex. The LHC is expected to be the highest-energy particle collider in the world for at least another two decades, and it will take several years of data-taking to significantly improve upon the integrated luminosity of the 2016-2018 data-taking period. Assuming that Run 3 of the LHC provides approximately \SI{300}{\fbinv} of \SI{14}{\TeV} proton-proton collisions by the end of 2024~\cite{run3_constraints, lhc_schedule}, for example, repeating this same analysis would likely only increase the reach in top squark mass reach by a few hundred~\si{\GeV}~\cite{collider_reach}. On the other hand, there are several potential changes to the analysis strategy that may be worth pursuing.

The most straightforward improvement would be to study the electron and muon identification requirements with an eye to improving the signal efficiency, especially at large \ad. In particular, the missing inner hit and pixel hit requirements applied to electrons and muons, respectively, in the current analysis effectively limit the maximum LLP decay length to the radius of the CMS pixel detector, which is \SI{16}{\cm}. Any gains in signal efficiency would of course have to be balanced against the likely increase in the mismeasurement background. Thinking along similar lines, it may be interesting to investigate the effects of relaxing the lepton isolation requirement.

A more challenging angle would be to explicitly consider tau leptons in the final state. The analysis presented here is sensitive to displaced taus that decay leptonically to electrons and muons, but a future analysis could likely expand this sensitivity by explicitly studying the \ad behavior of displaced taus. Given the tau decay branching fractions~\cite{pdg_2020}, the largest gain would likely come from considering hadronic tau decays, though this route would also likely represent a considerable challenge.

Finally, one could perform an analysis similar to the one presented here but specifically target new low-mass long-lived particles. The lepton \pt requirements imposed by the trigger limit the low-mass sensitivity of the current analysis. One possible approach would be to adopt a different triggering strategy in the next data-taking period, but it may be that CMS has already collected the ideal dataset in which to perform such a search. In 2018, CMS debuted a novel trigger strategy in which specialized triggers collected approximately ten billion unbiased B-hadron-decay events~\cite{cms_b_parking}. The triggers use a tag-and-probe strategy that actually require the presence of at least one displaced muon whose \pt can be as low as \SI{7}{\GeV}. The trade-off is that most of the muons will be embedded in \cPqb-tagged jets, which will likely necessitate changes to the analysis strategy. Such a search could be an interesting way to cover new ground with existing data, and may be of particular interest given the growing tension between experiment and SM predictions of lepton universality~\cite{lhcb} and the muon anomalous magnetic moment~\cite{g_minus_two}.